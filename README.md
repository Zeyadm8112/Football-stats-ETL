# âš½ Football ETL Pipeline with Airflow

This project is a full **ETL pipeline** built in Python using Apache Airflow. It extracts football match data from the [API-FOOTBALL](https://www.api-football.com/) API, transforms it using pandas, and loads the structured data into a **PostgreSQL** database hosted on a **Debian Linux server (Alibaba Cloud ECS)**.
---

![etl_preview](https://github.com/user-attachments/assets/85f7fae0-c16d-4ad9-b359-f83a61f99866)
---

## âœ… Pipeline Status

- âœ… Extract phase â€“ *Fixtures, Teams, Squads*
- âœ… Transform phase â€“ *Null handling, schema cleaning, type conversion*
- âœ… Load phase â€“ *PostgreSQL database*
- ðŸ› ï¸ Fully orchestrated with Airflow tasks & dependencies

## ðŸ“Œ Features

- ðŸ” Daily scheduled DAG runs
- ðŸ” Extracts today's fixtures, participating teams, and full squads
- ðŸ§¹ Cleans and transforms raw JSON data into SQL-ready tables
- ðŸ˜ PostgreSQL integration on cloud
- â˜ï¸ Runs on Alibaba Cloud ECS with Linux (Debian)
- ðŸ”— Modular, extensible Python scripts for testing or future ML

---

## ðŸ› ï¸ Tech Stack

| Layer         | Tool/Technology         |
|---------------|-------------------------|
| Orchestration | Apache Airflow          |
| Language      | Python 3                |
| Data Source   | API-FOOTBALL.io         |
| Processing    | pandas                  |
| Database      | PostgreSQL              |
| Cloud         | Alibaba Cloud ECS       |
| OS            | Debian Linux            |

---

## ðŸ› ï¸ Project Structure
```
.
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ dag.py # Airflow DAG with all ETL tasks
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ extract.py # Extract logic: fixtures, teams, squads
â”‚ â”œâ”€â”€ transform.py # Transform logic: clean, format
â”‚ â””â”€â”€ load.py # Load logic: push to PostgreSQL
â”œâ”€â”€ docker-compose.yaml
â””â”€â”€ README.md

```


---

## ðŸ“¥ Extract Phase

Extracts 3 sets of data from the API:

- `fetch_fixtures()` â€“ todayâ€™s matches
- `extract_teams_id()` â€“ team IDs from fixtures
- `fetch_teams_info()` â€“ metadata for each team
- `fetch_teams_players_squads()` â€“ player-level data per team

---

## ðŸ”„ Transform Phase

### ðŸ—“ Fixtures Transformation
- Remove rows where `match_id`, `home_team_id`, or `away_team_id` are `null`
- Exclude canceled matches
- Fill missing values with defaults:
  - `country` â†’ `'Unknown'`
  - `venue` â†’ `'Unknown'`
  - `home_team_score` and `away_team_score` â†’ `0`
- Convert fields to appropriate types (e.g., strings, integers) for SQL compatibility

### ðŸŸ Teams Transformation
- Drop rows with missing `team_id`, `team_name`, or `venue_id`
- Fill missing values with:
  - `team_code` â†’ `'UNK'`
  - `country` â†’ `'Unknown'`
  - `city` â†’ `'Unknown'`
  - `founded` â†’ `0`
  - `venue_name` â†’ `'Unknown'`

### ðŸ‘¥ Squads Transformation
- Fill missing string values such as `name`, `team_name`, and `position`
- Convert and fill numeric fields like `age` and `number` to integers

---
## ðŸ§© Load Phase

- Load the cleaned `fixtures`, `teams`, and `squads` datasets into PostgreSQL tables
- Connection is securely established to a remote PostgreSQL server hosted on **Debian Linux (Alibaba Cloud)**
---

## ðŸ“… DAG Workflow

```mermaid
graph TD
    A[fetch_fixtures_task] --> B[extract_teams_task]
    B --> C[extract_team_info_task]
    C --> D[extract_team_squad_task]
    C --> E[transform_teams_task] --> F[load_teams_task]
    D --> G[transform_squads_task] --> H[load_squads_task]
    A --> I[transform_matches_task] --> J[load_fixtures_task]

```

---

ðŸ‘¤ Author

Zeyad Mohamed

Python Developer | Data Engineer in Progress
